{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ztchen/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers.utils.dummy_vision_objects import ImageGPTFeatureExtractor\n",
    "import os\n",
    "from PIL import ImageDraw, ImageFont, Image\n",
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "from transformers import ViTForImageClassification, TrainingArguments, Trainer, ViTFeatureExtractor\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving data files: 100%|██████████| 35011/35011 [00:00<00:00, 37698.43it/s] \n",
      "Resolving data files: 100%|██████████| 3970/3970 [00:00<00:00, 9430.28it/s] \n",
      "Using custom data configuration default-146ea55b81da53a9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset imagefolder/default to /home/ztchen/.cache/huggingface/datasets/imagefolder/default-146ea55b81da53a9/0.0.0/48efdc62d40223daee675ca093d163bcb6cb0b7d7f93eb25aebf5edca72dc597...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files #0:   0%|          | 0/2189 [00:00<?, ?obj/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #0: 100%|██████████| 2189/2189 [00:00<00:00, 13895.00obj/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #4: 100%|██████████| 2188/2188 [00:00<00:00, 19368.61obj/s]\n",
      "Downloading data files #2: 100%|██████████| 2189/2189 [00:00<00:00, 13915.35obj/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #5: 100%|██████████| 2188/2188 [00:00<00:00, 37510.52obj/s]\n",
      "Downloading data files #3: 100%|██████████| 2188/2188 [00:00<00:00, 19228.40obj/s]\n",
      "Downloading data files #1: 100%|██████████| 2189/2189 [00:00<00:00, 19639.97obj/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #13: 100%|██████████| 2188/2188 [00:00<00:00, 22384.46obj/s]\n",
      "Downloading data files #8: 100%|██████████| 2188/2188 [00:00<00:00, 20308.30obj/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #14: 100%|██████████| 2188/2188 [00:00<00:00, 21846.89obj/s]\n",
      "Downloading data files #11: 100%|██████████| 2188/2188 [00:00<00:00, 35331.06obj/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #12: 100%|██████████| 2188/2188 [00:00<00:00, 20690.62obj/s]\n",
      "Downloading data files #9: 100%|██████████| 2188/2188 [00:00<00:00, 31222.08obj/s]\n",
      "Downloading data files #6: 100%|██████████| 2188/2188 [00:00<00:00, 24475.56obj/s]\n",
      "Downloading data files #7: 100%|██████████| 2188/2188 [00:00<00:00, 35169.93obj/s]\n",
      "Downloading data files #15: 100%|██████████| 2188/2188 [00:00<00:00, 54951.27obj/s]\n",
      "Downloading data files #10: 100%|██████████| 2188/2188 [00:00<00:00, 57086.66obj/s]\n",
      "Downloading data files: 0it [00:00, ?it/s]\n",
      "Extracting data files: 0it [00:00, ?it/s]\n",
      "Downloading data files #0: 100%|██████████| 249/249 [00:00<00:00, 53282.06obj/s]\n",
      "Downloading data files #1: 100%|██████████| 249/249 [00:00<00:00, 55325.62obj/s]\n",
      "\n",
      "Downloading data files #2: 100%|██████████| 248/248 [00:00<00:00, 55524.04obj/s]\n",
      "\n",
      "\n",
      "Downloading data files #3: 100%|██████████| 248/248 [00:00<00:00, 54278.20obj/s]\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #4: 100%|██████████| 248/248 [00:00<00:00, 54142.59obj/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #5: 100%|██████████| 248/248 [00:00<00:00, 50272.46obj/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #6: 100%|██████████| 248/248 [00:00<00:00, 54700.64obj/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #8: 100%|██████████| 248/248 [00:00<00:00, 53103.30obj/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #7: 100%|██████████| 248/248 [00:00<00:00, 53784.25obj/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #9: 100%|██████████| 248/248 [00:00<00:00, 53513.09obj/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #10: 100%|██████████| 248/248 [00:00<00:00, 51846.05obj/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #11: 100%|██████████| 248/248 [00:00<00:00, 54391.73obj/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #12: 100%|██████████| 248/248 [00:00<00:00, 54454.37obj/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #13: 100%|██████████| 248/248 [00:00<00:00, 41958.27obj/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #14: 100%|██████████| 248/248 [00:00<00:00, 55839.99obj/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading data files #15: 100%|██████████| 248/248 [00:00<00:00, 45843.43obj/s]\n",
      "Downloading data files: 0it [00:00, ?it/s]\n",
      "Extracting data files: 0it [00:00, ?it/s]\n",
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset imagefolder downloaded and prepared to /home/ztchen/.cache/huggingface/datasets/imagefolder/default-146ea55b81da53a9/0.0.0/48efdc62d40223daee675ca093d163bcb6cb0b7d7f93eb25aebf5edca72dc597. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  6.22it/s]\n"
     ]
    }
   ],
   "source": [
    "def transform(example_batch):\n",
    "    # Take a list of PIL images and turn them to pixel values\n",
    "    inputs = feature_extractor([x for x in example_batch['image']], return_tensors='pt')\n",
    "\n",
    "    # Don't forget to include the labels!\n",
    "    inputs['label'] = example_batch['label']\n",
    "    return inputs\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"imagefolder\", data_files={\"train\": [\"./objects/train/**\", \"./objects/test/**\",], \"val\": \"./objects/val/**\"})\n",
    "\n",
    "prepared_ds = dataset.with_transform(transform)\n",
    "labels = dataset['train'].features['label'].names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.weight', 'pooler.dense.bias']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# pre-trained models\n",
    "model_name_or_path = 'google/vit-base-patch16-224-in21k'\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(model_name_or_path)\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    num_labels=len(labels),\n",
    "    id2label={str(i): c for i, c in enumerate(labels)},\n",
    "    label2id={c: str(i) for i, c in enumerate(labels)}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "  output_dir=\"./vit-base-beans-r9\",\n",
    "  per_device_train_batch_size=16,\n",
    "  evaluation_strategy=\"steps\",\n",
    "  num_train_epochs=4,\n",
    "  fp16=True,\n",
    "  save_steps=500,\n",
    "  eval_steps=500,\n",
    "  logging_steps=50,\n",
    "  learning_rate=2e-4,\n",
    "  save_total_limit=2,\n",
    "  remove_unused_columns=False,\n",
    "  push_to_hub=False,\n",
    "  report_to='tensorboard',\n",
    "  load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "def compute_metrics(p):\n",
    "    return metric.compute(predictions=np.argmax(p.predictions, axis=1), references=p.label_ids)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return {\n",
    "        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n",
    "        'labels': torch.tensor([x['label'] for x in batch])\n",
    "    }\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=prepared_ds[\"train\"],\n",
    "    eval_dataset=prepared_ds[\"val\"],\n",
    "    tokenizer=feature_extractor,\n",
    ")\n",
    "\n",
    "train_results = trainer.train()\n",
    "trainer.save_model()\n",
    "trainer.log_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_state()\n",
    "\n",
    "metrics = trainer.evaluate(prepared_ds['val'])\n",
    "trainer.log_metrics(\"test\", metrics)\n",
    "trainer.save_metrics(\"test\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference\n",
    "\n",
    "model_name_or_path = 'google/vit-base-patch16-224-in21k'\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(model_name_or_path)\n",
    "model = ViTForImageClassification.from_pretrained('./vit-base-beans-demo-v5/')\n",
    "model.cuda()\n",
    "\n",
    "# dataset = load_dataset(\"imagefolder\", data_files={\"train\": \"./objects/train/**\", \"test\": \"./objects/test/**\", \"val\": \"./objects/val/**\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = './objects/test/negative/'\n",
    "imgs = [cv2.imread(dir + '/' + i) for i in os.listdir(dir)[:300]]\n",
    "imgs = [cv2.cvtColor(img, cv2.COLOR_BGR2RGB) for img in imgs]\n",
    "\n",
    "inputs = feature_extractor(imgs, return_tensors=\"pt\")\n",
    "inputs['pixel_values'] = inputs['pixel_values'].cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "for i in logits.argmax(-1).cpu():\n",
    "    print(i == 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('augsv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea843e43e7fdee24bedfe5ba2ea7c6250bc624b630d9c43ad92a68373bafe07f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
